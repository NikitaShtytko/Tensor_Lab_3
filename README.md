Лабораторная работа №3
====
# Цель лабораторной работы
Исследовать влияние параметра “темп обучения” на процесс обучения нейронной сети на примере решения задачи классификации Food-101 с использованием техники обучения Transfer Learning

# 1. С использованием техники обучения Transfer Learning обучить нейронную сеть EfficientNet-B0 (предварительно обученную на базе изображений imagenet) для решения задачи классификации изображений Food-101 с использованием фиксированных темпов обучения 0.01, 0.001, 0.0001 
 
* Изменение темпов обучения от 0.1 до 0.0001
```
#optimizer=tf.optimizers.Adam(lr=0.01)
#optimizer=tf.optimizers.Adam(lr=0.001)
#optimizer=tf.optimizers.Adam(lr=0.0001)
```

 ### Графики обучения для сети EfficientNet-B0 с фиксированными темпами обучения 0.01, 0.001, 0.0001:
 
 * Оранжевый - темп 0.01 на тренировочной выборке
   Синий - темп 0.01 на валидационной выборке
   
 * Красный - темп 0.001 на тренировочной выборке
   Голубой - темп 0.001 на валидационной выборке
   
 * Розовый - темп 0.0001 на тренировочной выборке
   Зеленый - темп 0.0001 на валидационной выборке
  
 ***График метрики точности:*** 
<img src="./logs-adam/epoch_categorical_accuracy.svg">

 ***График функции потерь:*** 
<img src="./logs-adam/epoch_loss.svg">


### Анализ результатов:
Смотря на график метрики точности видно, что лучшее значения, достигаются при использовании темпов обучения 0.001, равное 87.92%, и 0.1, равное 87.32% . Смотря на график функции потерь видно, что минимальные потери были при темпах обучения 0.001 и 0.0001. Исходя из данных результатов можно сказать, что темп обучения 0.001 является оптимальным.


# Реализовать и применить в обучении следующие политики изменения темпаобучения, а также определить оптимальные параметры для каждой политики: Пошаговое затухание (Step Decay) и Экспоненциальное затухание (Exponential Decay)

* **Описание структуры** 


* 
```
exp
```
 
```
exp
```


 ### Графики обучения для предобученной нейронной сети EfficientNet-B0 с политикой изменения темпа обучения - пошаговое затухание
 

 ***График метрики точности:*** 
<img src="./graph/epoch_categorical_accuracy_step.svg">

 ***График функции потерь:*** 
 
<img src="./graph/epoch_loss_step.svg">

 ***Пояснение:*** 
 
<img src="./graph/com_step.jpg">

### Анализ результатов:
Смотря на график метрики точности и функции потерь видно, что лучшее значения, достигаются при использовании параметров initial_lrate = 0.001, drop = 0.5, epochs_drop = 5.0. Получилось значение точности равное 88.52%, что на 0.60% лучше, чем при фиксированном темпе обучение. Также при данных параметрах достигается наилучшее значение функции потерь равное 0.2313.

 ### Графики обучения для предобученной нейронной сети EfficientNet-B0 с политикой изменения темпа обучения - экспоненциальное затухание
 

 ***График метрики точности:*** 
<img src="./graph/epoch_categorical_accuracy_exp.svg">

 ***График функции потерь::*** 
 
<img src="./graph/epoch_loss_exp.svg">

 ***Пояснение:*** 
 
<img src="./graph/com_exp.jpg">

### Анализ результатов:
Смотря на график метрики точности и функции потерь видно, что лучшее значения, достигаются при использовании параметров initial_lrate = 0.01 и k = 0.25. Получилось значение точности равное 89.07%, что на 1.15% лучше, чем при фиксированном темпе обучение. 


 ### Итоговое сравнение оптимальных результатов
 

***График метрики точности:*** 
<img src="./graph/epoch_categorical_accuracy_opt.svg">

 ***График функции потерь::*** 
 
<img src="./graph/epoch_loss_opt.svg">

 ***Пояснение:*** 
 
<img src="./graph/com_opt.jpg">

### Анализ результатов:
* Из графика метрики точности, можно сказать что лучший результат равный 89.07% достигается при использовании политики изменения темпа обучения - экспоненциальное затухание, что на 1.15% лучше, чем при фиксированном темпе обучение, и на 0.55% лучше, чем при пошаговом затухании.

* Из графика функции потерь, можно сказать что лучший результат 0.2313 равный достигается при использовании политики изменения темпа обучения - пошаговом затухании, что на 0.1748 меньше чем при фиксированном темпе обучения, и на 0.0631 меньше чем при экспоненциальном затухании.

* Оптимальный результат получен при использовании политики изменения темпа обучения - экспоненциальное затухание.
